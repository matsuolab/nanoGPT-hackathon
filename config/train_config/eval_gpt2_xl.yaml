# evaluate the base gpt2
# n_layer=48, n_head=25, n_embd=1600
# 1558M parameters
defaults:
  - ../train
batch_size: 8
eval_iters: 500 # use more iterations to get good estimate
eval_only: true
wandb_log: false
init_from: 'gpt2-xl'
